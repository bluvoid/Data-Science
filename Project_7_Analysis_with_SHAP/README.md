# SHAP

SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.    
See https://pypi.org/project/shap/    
See https://github.com/slundberg/shap

<b> 20181125_SHAP.ipynb: </b>    
This notebook is dedicated to the explaination of the previous project, Project 1 Nutritional Analysis, using SHAP.
